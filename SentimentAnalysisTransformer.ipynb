{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ca03cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d6d0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pretrained transformer\n",
    "from transformers import RobertaTokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16aaf274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> </s> <pad> <unk>\n"
     ]
    }
   ],
   "source": [
    "init_token = tokenizer.cls_token\n",
    "eos_token = tokenizer.sep_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb3ee5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 1 3\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b55425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 1 3\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.cls_token_id\n",
    "eos_token_idx = tokenizer.sep_token_id\n",
    "pad_token_idx = tokenizer.pad_token_id\n",
    "unk_token_idx = tokenizer.unk_token_id\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82e734f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "maxInputLength = tokenizer.max_model_input_sizes['roberta-base']\n",
    "print(maxInputLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36524653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:maxInputLength-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c15977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.legacy import data\n",
    "TEXT = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dfd3353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading aclImdb_v1.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\New_\\.data\\imdb\\aclImdb_v1.tar.gz: 100%|███████████████████████████████████████| 84.1M/84.1M [00:19<00:00, 4.26MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchtext.legacy import datasets\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "train_data, valid_data = train_data.split(random_state = random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "851e0bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 481/481 [00:00<00:00, 59682.88B/s]\n",
      "100%|████████████████████████████████████████████████████████████████| 501200538/501200538 [01:11<00:00, 7057379.41B/s]\n"
     ]
    }
   ],
   "source": [
    "LABEL.build_vocab(train_data)\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE, \n",
    "    device = device)\n",
    "\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "import torch.nn as nn\n",
    "rob = RobertaModel.from_pretrained('roberta-base')\n",
    "\n",
    "class RobertaSentiment(nn.Module):\n",
    "    def __init__(self,\n",
    "                 rob,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.rob = rob\n",
    "        embedding_dim = rob.config.to_dict()['hidden_size']\n",
    "        # Define rnn\n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          hidden_dim,\n",
    "                          num_layers = n_layers,\n",
    "                          bidirectional = bidirectional,\n",
    "                          batch_first = True,\n",
    "                          dropout = 0 if n_layers < 2 else dropout)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        with torch.no_grad():\n",
    "        _, thehiddenlayer = self.rnn(self.rob(text)[0])\n",
    "        if self.rnn.bidirectional:\n",
    "            thehiddenlayer = self.dropout(torch.cat((thehiddenlayer[-2,:,:], thehiddenlayer[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            thehiddenlayer = self.dropout(thehiddenlayer[-1,:,:])\n",
    "        \n",
    "        output = self.out(thehiddenlayer)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00377b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 127,404,801 trainable parameters\n",
      "The model has 127,404,801 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "model = RobertaSentiment(rob,\n",
    "                         HIDDEN_DIM,\n",
    "                         OUTPUT_DIM,\n",
    "                         N_LAYERS,\n",
    "                         BIDIRECTIONAL,\n",
    "                         DROPOUT)\n",
    "\n",
    "\n",
    "def countPra(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {countPra(model):,} trainable parameters')\n",
    "\n",
    "for name, param in model.named_parameters():                \n",
    "    if name.startswith('bert'):\n",
    "        param.requires_grad = False\n",
    "        \n",
    "def reCountPra(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {reCountPra(model):,} trainable parameters')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b88be14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0 \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(batch.text).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99171bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            predictions = model(batch.text).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            \n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61813972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f936e70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 309m 53s\n",
      "\tTrain Loss: 0.386 | Train Acc: 80.99%\n",
      "\t Val. Loss: 0.224 |  Val. Acc: 91.75%\n",
      "Epoch: 02 | Epoch Time: 295m 11s\n",
      "\tTrain Loss: 0.203 | Train Acc: 92.13%\n",
      "\t Val. Loss: 0.176 |  Val. Acc: 93.39%\n",
      "Epoch: 03 | Epoch Time: 289m 45s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.19%\n",
      "\t Val. Loss: 0.188 |  Val. Acc: 93.03%\n",
      "Epoch: 04 | Epoch Time: 286m 16s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.08%\n",
      "\t Val. Loss: 0.177 |  Val. Acc: 93.47%\n",
      "Epoch: 05 | Epoch Time: 288m 49s\n",
      "\tTrain Loss: 0.155 | Train Acc: 94.36%\n",
      "\t Val. Loss: 0.178 |  Val. Acc: 93.65%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "        \n",
    "    end_time = time.time()\n",
    "        \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "        \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'sentiment_model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44c1f316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.162 | Test Acc: 94.00%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('sentiment_model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8fc707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fe8a821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarityDetection(content, inModel, inTokenizer):\n",
    "    model.eval()\n",
    "    tokens = tokenizer.tokenize(content)\n",
    "    tokens = tokens[:maxInputLength-2]\n",
    "    indexed = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens) + [eos_token_idx]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    prediction = torch.sigmoid(model(tensor))\n",
    "    \n",
    "    if prediction.item() > 0.5:\n",
    "        return \"Positive\"\n",
    "    elif prediction.item() < 0.5:\n",
    "        return \"Negative\"\n",
    "    else:\n",
    "        return \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd5cf38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>location</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>create_time</th>\n",
       "      <th>content</th>\n",
       "      <th>image</th>\n",
       "      <th>Cleaned content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>singapore transport</td>\n",
       "      <td>singapore</td>\n",
       "      <td>lower octane petrol prices dip below 3 a litre</td>\n",
       "      <td>christopher tan</td>\n",
       "      <td>2022-04-04 12:19:38</td>\n",
       "      <td>singapore pump prices have fallen by five cent...</td>\n",
       "      <td>https://static1.straitstimes.com.sg/s3fs-publi...</td>\n",
       "      <td>singapore pump prices have fallen by five cent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singapore</td>\n",
       "      <td>singapore</td>\n",
       "      <td>at least 1 month waiting time for new s'pore p...</td>\n",
       "      <td>isabelle liew</td>\n",
       "      <td>2022-04-04 10:21:45</td>\n",
       "      <td>singapore singaporeans who apply for a new pas...</td>\n",
       "      <td>https://static1.straitstimes.com.sg/s3fs-publi...</td>\n",
       "      <td>singapore singaporeans who apply for a new pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singapore housing</td>\n",
       "      <td>singapore</td>\n",
       "      <td>work on 9 hdb commercial complexes hit by dela...</td>\n",
       "      <td>michelle ng</td>\n",
       "      <td>2022-04-04 05:00:00</td>\n",
       "      <td>singapore work at eight housing board commerci...</td>\n",
       "      <td>https://static1.straitstimes.com.sg/s3fs-publi...</td>\n",
       "      <td>singapore work at eight housing board commerci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>singapore</td>\n",
       "      <td>singapore</td>\n",
       "      <td>online sales beef up family's butcher business...</td>\n",
       "      <td>kolette lim</td>\n",
       "      <td>2022-04-04 05:00:00</td>\n",
       "      <td>singapore she saw her parents struggling as bu...</td>\n",
       "      <td>https://static1.straitstimes.com.sg/s3fs-publi...</td>\n",
       "      <td>singapore she saw her parents struggling as bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singapore</td>\n",
       "      <td>singapore</td>\n",
       "      <td>undergrads adapt alcohol delivery offerings to...</td>\n",
       "      <td>kolette lim</td>\n",
       "      <td>2022-04-04 05:00:00</td>\n",
       "      <td>singapore when mr chai wan lin and mr tneoh yu...</td>\n",
       "      <td>https://static1.straitstimes.com.sg/s3fs-publi...</td>\n",
       "      <td>singapore when mr chai wan lin and mr tneoh yu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category   location  \\\n",
       "0  singapore transport  singapore   \n",
       "1            singapore  singapore   \n",
       "2    singapore housing  singapore   \n",
       "3            singapore  singapore   \n",
       "4            singapore  singapore   \n",
       "\n",
       "                                               title           author  \\\n",
       "0     lower octane petrol prices dip below 3 a litre  christopher tan   \n",
       "1  at least 1 month waiting time for new s'pore p...    isabelle liew   \n",
       "2  work on 9 hdb commercial complexes hit by dela...      michelle ng   \n",
       "3  online sales beef up family's butcher business...      kolette lim   \n",
       "4  undergrads adapt alcohol delivery offerings to...      kolette lim   \n",
       "\n",
       "          create_time                                            content  \\\n",
       "0 2022-04-04 12:19:38  singapore pump prices have fallen by five cent...   \n",
       "1 2022-04-04 10:21:45  singapore singaporeans who apply for a new pas...   \n",
       "2 2022-04-04 05:00:00  singapore work at eight housing board commerci...   \n",
       "3 2022-04-04 05:00:00  singapore she saw her parents struggling as bu...   \n",
       "4 2022-04-04 05:00:00  singapore when mr chai wan lin and mr tneoh yu...   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://static1.straitstimes.com.sg/s3fs-publi...   \n",
       "1  https://static1.straitstimes.com.sg/s3fs-publi...   \n",
       "2  https://static1.straitstimes.com.sg/s3fs-publi...   \n",
       "3  https://static1.straitstimes.com.sg/s3fs-publi...   \n",
       "4  https://static1.straitstimes.com.sg/s3fs-publi...   \n",
       "\n",
       "                                     Cleaned content  \n",
       "0  singapore pump prices have fallen by five cent...  \n",
       "1  singapore singaporeans who apply for a new pas...  \n",
       "2  singapore work at eight housing board commerci...  \n",
       "3  singapore she saw her parents struggling as bu...  \n",
       "4  singapore when mr chai wan lin and mr tneoh yu...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up content\n",
    "import pandas as pd\n",
    "df = pd.read_json('clean.json')\n",
    "\n",
    "import re\n",
    "\n",
    "def cleanContentText(content):\n",
    "    content = re.sub('[^A-Za-z]+', ' ', content)\n",
    "    return content\n",
    "\n",
    "df['Temp Content'] = df['content'].apply(cleanContentText)\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "labelDic = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N': wordnet.NOUN, 'R': wordnet.ADV}\n",
    "\n",
    "def getSentiLabel(content):\n",
    "    senTags = pos_tag(word_tokenize(content))\n",
    "    labels = []\n",
    "    for word, label in senTags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "            labels.append(tuple([word, labelDic.get(label[0])]))\n",
    "    return labels\n",
    "\n",
    "df['Word Labels'] = df['Temp Content'].apply(getSentiLabel)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnetLem = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(inLabels):\n",
    "    result = \"\"\n",
    "    for word, label in inLabels:\n",
    "        if not label:\n",
    "            result = result + \" \" + word\n",
    "        else:\n",
    "            temp = wordnetLem.lemmatize(word, pos = label)\n",
    "            result = result + \" \" + temp\n",
    "    return result\n",
    "\n",
    "df['Cleaned Content'] = df['Word Labels'].apply(lemmatize)\n",
    "df.drop(columns=['Word Labels', 'Temp Content'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a8843c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>location</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>create_time</th>\n",
       "      <th>content</th>\n",
       "      <th>image</th>\n",
       "      <th>Cleaned content</th>\n",
       "      <th>Sentiment Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>singapore transport</td>\n",
       "      <td>singapore</td>\n",
       "      <td>lower octane petrol prices dip below 3 a litre</td>\n",
       "      <td>christopher tan</td>\n",
       "      <td>2022-04-04 12:19:38</td>\n",
       "      <td>singapore pump prices have fallen by five cent...</td>\n",
       "      <td>https://static1.straitstimes.com.sg/s3fs-publi...</td>\n",
       "      <td>singapore pump prices have fallen by five cent...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singapore</td>\n",
       "      <td>singapore</td>\n",
       "      <td>at least 1 month waiting time for new s'pore p...</td>\n",
       "      <td>isabelle liew</td>\n",
       "      <td>2022-04-04 10:21:45</td>\n",
       "      <td>singapore singaporeans who apply for a new pas...</td>\n",
       "      <td>https://static1.straitstimes.com.sg/s3fs-publi...</td>\n",
       "      <td>singapore singaporeans who apply for a new pas...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>singapore housing</td>\n",
       "      <td>singapore</td>\n",
       "      <td>work on 9 hdb commercial complexes hit by dela...</td>\n",
       "      <td>michelle ng</td>\n",
       "      <td>2022-04-04 05:00:00</td>\n",
       "      <td>singapore work at eight housing board commerci...</td>\n",
       "      <td>https://static1.straitstimes.com.sg/s3fs-publi...</td>\n",
       "      <td>singapore work at eight housing board commerci...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>singapore</td>\n",
       "      <td>singapore</td>\n",
       "      <td>online sales beef up family's butcher business...</td>\n",
       "      <td>kolette lim</td>\n",
       "      <td>2022-04-04 05:00:00</td>\n",
       "      <td>singapore she saw her parents struggling as bu...</td>\n",
       "      <td>https://static1.straitstimes.com.sg/s3fs-publi...</td>\n",
       "      <td>singapore she saw her parents struggling as bu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singapore</td>\n",
       "      <td>singapore</td>\n",
       "      <td>undergrads adapt alcohol delivery offerings to...</td>\n",
       "      <td>kolette lim</td>\n",
       "      <td>2022-04-04 05:00:00</td>\n",
       "      <td>singapore when mr chai wan lin and mr tneoh yu...</td>\n",
       "      <td>https://static1.straitstimes.com.sg/s3fs-publi...</td>\n",
       "      <td>singapore when mr chai wan lin and mr tneoh yu...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              category   location  \\\n",
       "0  singapore transport  singapore   \n",
       "1            singapore  singapore   \n",
       "2    singapore housing  singapore   \n",
       "3            singapore  singapore   \n",
       "4            singapore  singapore   \n",
       "\n",
       "                                               title           author  \\\n",
       "0     lower octane petrol prices dip below 3 a litre  christopher tan   \n",
       "1  at least 1 month waiting time for new s'pore p...    isabelle liew   \n",
       "2  work on 9 hdb commercial complexes hit by dela...      michelle ng   \n",
       "3  online sales beef up family's butcher business...      kolette lim   \n",
       "4  undergrads adapt alcohol delivery offerings to...      kolette lim   \n",
       "\n",
       "          create_time                                            content  \\\n",
       "0 2022-04-04 12:19:38  singapore pump prices have fallen by five cent...   \n",
       "1 2022-04-04 10:21:45  singapore singaporeans who apply for a new pas...   \n",
       "2 2022-04-04 05:00:00  singapore work at eight housing board commerci...   \n",
       "3 2022-04-04 05:00:00  singapore she saw her parents struggling as bu...   \n",
       "4 2022-04-04 05:00:00  singapore when mr chai wan lin and mr tneoh yu...   \n",
       "\n",
       "                                               image  \\\n",
       "0  https://static1.straitstimes.com.sg/s3fs-publi...   \n",
       "1  https://static1.straitstimes.com.sg/s3fs-publi...   \n",
       "2  https://static1.straitstimes.com.sg/s3fs-publi...   \n",
       "3  https://static1.straitstimes.com.sg/s3fs-publi...   \n",
       "4  https://static1.straitstimes.com.sg/s3fs-publi...   \n",
       "\n",
       "                                     Cleaned content Sentiment Label  \n",
       "0  singapore pump prices have fallen by five cent...        Positive  \n",
       "1  singapore singaporeans who apply for a new pas...        Positive  \n",
       "2  singapore work at eight housing board commerci...        Positive  \n",
       "3  singapore she saw her parents struggling as bu...        Positive  \n",
       "4  singapore when mr chai wan lin and mr tneoh yu...        Positive  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict sentiment result\n",
    "df['Sentiment Label'] = df['Cleaned content'].apply(polarityDetection, inModel = model, inTokenizer = tokenizer)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ccc4e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive    13008\n",
       "Negative      277\n",
       "Name: Sentiment Label, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiResultStat = df['Sentiment Label'].value_counts()\n",
    "sentiResultStat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef705f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
